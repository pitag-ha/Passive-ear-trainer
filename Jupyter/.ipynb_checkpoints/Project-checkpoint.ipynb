{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import librosa, librosa.display\n",
    "import IPython.display as ipd\n",
    "import vamp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.fftpack as fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pprint = pp.pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Autumn Leaves - Yenne Lee plays 2004 Pepe Romero Jr.-HxGT5z6d-GA.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Beatles - I wanna hold your hand - live.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Beatles - I wanna hold your hand -studio.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Dumb Ways to Die-IJNR2EpS0jw.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Queen - I Want to Break Free (Official Lyric Video)-WUOtCLOXgm8.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Selena Gomez, Marshmello - Wolves (Official Music Video)-cH4E_t3m3xM.m4a'\n",
    "path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Ska-p Los hijos bastardos de la globalizacion con Letra-upnPasIYeMc.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/The Killers - Human-RIZdjT1472Y.m4a'\n",
    "#path = '/home/sonja/Dropbox/RC/Passive ear trainer/Songs/THE MUFFIN SONG (asdfmovie feat. Schmoyoho)-LACbVhgtx9I.m4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAS TO BE RUN FOR EVERY SONG\n",
    "song = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cow = librosa.load('/home/sonja/Dropbox/RC/Passive ear trainer/Songs/Kuh muht-TdheW61w4Co.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_analysis = vamp.collect(song[0], song[1], \"nnls-chroma:chordino\")['list']\n",
    "pprint(list(enumerate(song_analysis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_short_rec(short_rec, desired_num_samples, desired_vol):\n",
    "    bounds = [1113687, 1148687] #FIXME\n",
    "    current_vol = max(short_rec[0])\n",
    "    \n",
    "    sample = last_not_0_before_par(short_rec, bounds[1])\n",
    "    for _ in range(50):\n",
    "        sample = sign_change(short_rec, sample-1)\n",
    "    end_copy = sample\n",
    "\n",
    "    for _ in range(1000):\n",
    "        sample = sign_change(short_rec, sample-1)\n",
    "    beginning_copy = sample\n",
    "\n",
    "    extension = short_rec[0][bounds[0]:end_copy]\n",
    "    while len(extension) < desired_num_samples:\n",
    "        extension = np.concatenate((extension, short_rec[0][beginning_copy:end_copy]))\n",
    "        \n",
    "    extension = extension/current_vol*desired_vol\n",
    "    \n",
    "    return extension[:desired_num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cow_generator(amp, rate):\n",
    "    if rate != cow[1]:\n",
    "        return False\n",
    "    def f(num_samples):\n",
    "        return extend_short_rec(cow, num_samples, amp)\n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_not_0_before_par(rec, par):\n",
    "    ind = par\n",
    "    while rec[0][ind] == 0:\n",
    "        ind -= 1\n",
    "    return ind\n",
    "\n",
    "def first_0_before_par(rec, par):\n",
    "    ind = par\n",
    "    while rec[0][ind] != 0:\n",
    "        ind -= 1\n",
    "    return ind\n",
    "\n",
    "def sign_change(rec, par):\n",
    "    ind = par\n",
    "    while rec[0][ind] * rec[0][par] > 0:\n",
    "        ind -= 1\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_by_num_samples(freq, num_samples, amp=1, rate=song[1]):\n",
    "    data = np.array([np.sin(2*np.pi*freq*librosa.samples_to_time(sample, rate))*amp for sample in range(num_samples)], dtype=np.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_generator(freq, amp, rate):\n",
    "    def f(num_samples):\n",
    "        return note_by_num_samples(freq, num_samples, amp, rate)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encr_notes = {'C':0, 'C#':1, 'Db':1, 'D':2, 'D#':3, 'Eb':3, 'E':4, 'Fb':4, 'E#':5, 'F':5, 'F#':6, 'Gb':6, 'G':7, 'G#':8, 'Ab':8, 'A':9, 'A#':10, 'Bb':10, 'B':11, 'Cb':11, 'B#':0}\n",
    "\n",
    "depr_flat_notes = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'Gb', 'G', 'Ab', 'A', 'Bb', 'B']\n",
    "decr_sharp_notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_deg_in_semitones = {1:0, 2:2, 3:4, 4:5, 5:7, 6:9, 7:11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a tonality and a scale degree, find the chord corresponding to the scale degree in the given tonality\n",
    "def absolute_chord(tonality, scale_deg):\n",
    "    encr_chord = (encr_notes[tonality] + scale_deg_in_semitones[scale_deg]) % 12\n",
    "    if len(tonality) > 1 and tonality[1] == 'b':\n",
    "        chord = decr_flat_notes[encr_chord]\n",
    "    else:\n",
    "        chord = decr_sharp_notes[encr_chord]\n",
    "    return chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bass_freq = {'C':65.41, 'C#':69.30, 'D':73.42, 'D#':77.78, 'E':82.41, 'F':87.31, 'F#':92.50, 'G':98.00, 'G#':103.83, 'A':110.00, 'A#':116.54, 'B':123.47}\n",
    "high_pitch_freq = {'C':130.81, 'C#':138.59, 'D':146.83, 'D#':155.56, 'E':164.81, 'F':174.61, 'F#':185.00, 'G':196.00, 'G#':207.65, 'A':220.00, 'A#':233.08, 'B':246.94}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bounds_samples(song_analysis, chord):\n",
    "    #bounds_chord = [librosa.time_to_samples(t, song[1]) for t in timestamps_chord]\n",
    "\n",
    "    pairs = list(zip(song_analysis[:-1], song_analysis[1:]))\n",
    "    time_bounds = [(float(item1['timestamp']), float(item2['timestamp'])) for item1, item2 in pairs if re.match(re.escape(chord)+r'.*', item1['label'])]\n",
    "    bounds = [librosa.time_to_samples(t, song[1])for t in time_bounds]\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_amplitude_rel_song(song, strength):\n",
    "    song_intensity = max(song[0])\n",
    "    return song_intensity*strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_to_add(song_analysis, song_length, chord, timber, amp, rate):\n",
    "    if timber == 'cow':\n",
    "        note_generator = cow_generator(amp, rate)\n",
    "        if not note_generator:\n",
    "            'Sorry, the cow is tired of mooing. Please, choose a different timber!'\n",
    "    else:\n",
    "        if timber == 'low_pitch_synth':\n",
    "            freq = bass_freq[chord]\n",
    "        else:\n",
    "            freq = high_pitch_freq[chord]\n",
    "        note_generator = synth_generator(freq, amp, rate)\n",
    "    \n",
    "    bounds_chord = find_bounds_samples(song_analysis, chord)\n",
    "    add_to_song = np.zeros(song_length)\n",
    "    for beginning, end in bounds_chord:\n",
    "        if end > song_length:\n",
    "            end = song_length\n",
    "        add = note_generator(end - beginning)\n",
    "        add_to_song[beginning:end] = add\n",
    "        \n",
    "    return add_to_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tonality(song_analysis):\n",
    "    #look for a dominant chord: TO DO\n",
    "    \n",
    "    #find last chord\n",
    "    last_chord_index = -1\n",
    "    while song_analysis[last_chord_index]['label'] == 'N':\n",
    "        last_chord_index -= 1\n",
    "    last_chord = song_analysis[last_chord_index]['label']\n",
    "    \n",
    "    # find the chord that is played the most\n",
    "    list_of_chords = [chord['label'] for chord in song_analysis]\n",
    "    numb_appearance_chord2 = collections.Counter(list_of_chords)\n",
    "    most_appearing_chord = numb_appearance_chord2.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "    sign = ''\n",
    "    if len(most_appearing_chord) > 1:\n",
    "        if most_appearing_chord[1] == '#' or most_appearing_chord[1] == 'b':\n",
    "            sign = most_appearing_chord[1]\n",
    "\n",
    "    tonality = most_appearing_chord[0] + sign\n",
    "    \n",
    "    certainty = True\n",
    "    if last_chord != most_appearing_chord:\n",
    "        certeinty = False\n",
    "        \n",
    "    return tonality, certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_deg = 1 # 1,2,3,4,5,6 or 7\n",
    "timber = 'low_pitch_synth' # 'low_pitch_synth', 'high_pitch_synth' or 'cow'\n",
    "amp = 1/2 # 1/2, 1, 2 \n",
    "\n",
    "tonality, certainty = find_tonality(song_analysis)\n",
    "if not certainty:\n",
    "    print('The tonality is probably wrong, sorry for that!')\n",
    "\n",
    "chord = absolute_chord(tonality, scale_deg)\n",
    "length = len(song[0])\n",
    "to_add = generate_audio_to_add(song_analysis, length, chord, timber, amp, song[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = song[0] + to_add\n",
    "print(len(to_add))\n",
    "print(len(song[0]))\n",
    "print(tonality)\n",
    "bounds = find_bounds_samples(song_analysis, tonality)\n",
    "beginning, end = bounds[4]\n",
    "ipd.Audio(output, rate=song[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is not necessary anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAS TO BE RUN FOR EVERY SONG\n",
    "#Compute the chord that corresponds to a certain scale degree:\n",
    "scale_degree = 1\n",
    "chord = notes_sharp_medium_pitch[(encr_notes[tonality] + scale_degree_in_semitones[scale_degree]) % 12]\n",
    "print(chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAS TO BE RUN FOR EVERY SONG\n",
    "#Find the time stamps in between which the chord corresponding to the chosen scale degree appears in the song:\n",
    "chord_pairs = list(zip(chords[:-1], chords[1:]))\n",
    "timestamps_chord = [ (float(c[0]['timestamp']), float(c[1]['timestamp'])) for c in chord_pairs if re.match(re.escape(chord[0])+r'.*', c[0]['label'])]\n",
    "bounds_chord = [librosa.time_to_samples(t, song[1]) for t in timestamps_chord]\n",
    "lables_chord = [c[0]['label'] for c in chord_pairs if re.match(re.escape(chord[0])+r'.*', c[0]['label'])]\n",
    "\n",
    "#chord_number = 2\n",
    "#print(lables_chord[chord_number])\n",
    "#ipd.Audio(song[0][bounds_chord[chord_number][0]:bounds_chord[chord_number][1]], rate=song[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Has TO BE TUN FOR EVERY SONG\n",
    "#Compute highest amplitude in the song:\n",
    "max_amplitude = max(song[0])\n",
    "print(max_amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAS TO BE RUN FOR EVERY SONG\n",
    "#Generate the output (audio of song plus the base note of the chord corresponding to the scale degree chosen every time that chord appears):\n",
    "add_to_song = np.zeros(len(song[0]))\n",
    "for beginning, end in bounds_chord:\n",
    "    if end > len(song[0]):\n",
    "        end = len(song[0])\n",
    "    add = note_by_num_samples(chord[1] , end-beginning, amp=(max_amplitude)*5)\n",
    "    add_to_song[beginning:end] = add\n",
    "    \n",
    "output = song[0] + add_to_song\n",
    "ipd.Audio(output, rate=song[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cow = np.zeros(len(song[0]))\n",
    "max_num_samples = max([end-beginning for beginning, end in bounds_chord])\n",
    "long_cow = long_enough_ignoring_frequencies(max_num_samples)\n",
    "for beginning, end in bounds_chord:\n",
    "    if end > len(song[0]):\n",
    "        end = len(song[0])\n",
    "    add = long_cow[:(end-beginning)]\n",
    "    add_cow[beginning:end] = add\n",
    "\n",
    "output = song[0] + add_cow\n",
    "ipd.Audio(output, rate=song[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the output (audio of song plus the base note of the chord corresponding to the scale degree chosen every time that chord appears):\n",
    "add_to_song = np.zeros(len(song[0]))\n",
    "for beginning, end in bounds_chord:\n",
    "    if end > len(song[0]):\n",
    "        end = len(song[0])\n",
    "    add = note_by_num_samples(chord[1] , end-beginning, amp=max_amplitude)\n",
    "    add_to_song[beginning:end] = add\n",
    "    \n",
    "output = song[0] + add_to_song\n",
    "ipd.Audio(output, rate=song[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computations for for getting the bounds of the cow sample between which the cow moos\n",
    "cow_chords = vamp.collect(cow[0], cow[1], \"nnls-chroma:chordino\")['list']\n",
    "label = 'N'\n",
    "ind = 0\n",
    "while label == 'N':\n",
    "    ind += 1\n",
    "    label = cow_chords[ind]['label']\n",
    "beginning_ind = ind\n",
    "print(beginning_ind)\n",
    "while label != 'N':\n",
    "    ind += 1\n",
    "    label = cow_chords[ind]['label']\n",
    "end_ind = ind - 1\n",
    "print(end_ind)\n",
    "\n",
    "timestamps_cow = [float(cow_chords[beginning_ind]['timestamp']), float(cow_chords[2]['timestamp'])]\n",
    "bounds_cow = [librosa.time_to_samples(t, cow[1]) for t in timestamps_cow]\n",
    "\n",
    "bounds_cow[0]=bounds_cow[0]-25000\n",
    "bounds_cow[1]=bounds_cow[0]+35000\n",
    "print(bounds_cow)\n",
    "cow_in_F = cow[0][bounds_cow[0]:bounds_cow[1]]\n",
    "ipd.Audio(cow_in_F, rate=cow[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cow\n",
    "last_int_sample = last_not_0_before_par(bounds_cow[1])\n",
    "sample = last_int_sample\n",
    "for _  in range(50):\n",
    "    sample = sign_change(sample-1)\n",
    "last_sample_extension = sample\n",
    "\n",
    "for _  in range(1000):\n",
    "    sample = sign_change(sample-1)\n",
    "first_sample_extension = sample\n",
    "    \n",
    "#first_sample_extension = sample\n",
    "print(last_int_sample)\n",
    "print(first_sample_extension)\n",
    "\n",
    "long_sample_cow = cow[0][bounds_cow[0]:bounds_cow[1]]\n",
    "for _ in range(10):\n",
    "    long_sample_cow = np.concatenate((long_sample_cow, cow[0][first_sample_extension:last_sample_extension]))\n",
    "print(len(long_sample_cow))\n",
    "ipd.Audio(long_sample_cow, rate=cow[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cow\n",
    "def long_enough_ignoring_frequencies(num_samples):\n",
    "    output = cow[0][bounds_cow[0]:bounds_cow[1]]\n",
    "    while len(output) < num_samples:\n",
    "        output = np.concatenate((output, cow[0][first_sample_extension:last_sample_extension]))\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ear_trainer)",
   "language": "python",
   "name": "ear_trainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
